{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3e2118",
   "metadata": {},
   "source": [
    "# ADS Project 4: Machine Learning Fairness\n",
    "## Spring 2022\n",
    "#### Maximizing Accuracy under Fairness Constraints (C-LR and C-SVM) and Information Theoretic Measures for Fairness-Aware Feature selection (FFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8503c",
   "metadata": {},
   "source": [
    "Group 5: Chang Lu, Jiaxin Yu, Marcus Loke, Xiran Lin, Zaigham Khan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0916753",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Load Modules and Data](#load)\n",
    "3. [Logistic Regression](#lr)\n",
    "4. [SVM](#svm)\n",
    "5. [Information Theoretic Measures for Fairness-Aware Feature Selection (FFS)](#ffs)\n",
    "6. [Evaluation](#eval)\n",
    "7. [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e331e",
   "metadata": {},
   "source": [
    "## 1. Overview <a class=\"anchor\" id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b865a",
   "metadata": {},
   "source": [
    "+ The cleaned COMPAS dataset is provided in `../output/compas-scores-two-years(cleaned).csv`. The EDA and cleaning process is described in `../doc/eda_cleaning.html` and `eda_cleaning.Rmd`.\n",
    "\n",
    "\n",
    "+ Our team focused on three algorithms aimed at ensuring machine learning fairness. The algorithms are: maximizing accuracy under fairness constraints using C-LR and C-SVM (A2) and information theoretic measures for fairness-aware feature selection (FFS) (A7).\n",
    "\n",
    "\n",
    "+ Note that `utils.py` and `loss_funcs.py` are needed for **Section 3 and 4**: Maximizing accuracy under fairness constraints (C-SVM and C-LR) while `utils2.py` is needed for **Section 5**: Information theoretic measures for fairness-aware feature selection (FFS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645344a2",
   "metadata": {},
   "source": [
    "## 2. Load Modules and Data <a class=\"anchor\" id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e291cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils as ut\n",
    "import loss_funcs as lf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3e2668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.177294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt; 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2.029767</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.254156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.311803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt; 25</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>-0.536224</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age_cat              race  priors_count c_charge_degree  \\\n",
       "0    Male  25 - 45  African-American     -0.733607               F   \n",
       "1    Male     < 25  African-American      0.055928               F   \n",
       "2    Male  25 - 45         Caucasian      2.029767               F   \n",
       "3  Female  25 - 45         Caucasian     -0.733607               M   \n",
       "4    Male     < 25         Caucasian     -0.536224               F   \n",
       "\n",
       "   length_of_stay  two_year_recid  \n",
       "0       -0.177294               1  \n",
       "1       -0.350235               1  \n",
       "2       -0.254156               1  \n",
       "3       -0.311803               0  \n",
       "4       -0.350235               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../output/compas-scores-two-years(cleaned).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11af853",
   "metadata": {},
   "source": [
    "Encode categorical variables with dummy variables:\n",
    "+ `sex`: 1 for male and 0 for female\n",
    "+ `age_cat`: 2 for > 45, 1 for 25 - 45 and 0 for < 25\n",
    "+ `race`: 1 for caucasian and 0 for african-american\n",
    "+ `c_charge_degree`: 1 for F and 0 for M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d51b0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.177294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.029767</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.254156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.311803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.536224</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age_cat  race  priors_count  c_charge_degree  length_of_stay  \\\n",
       "0    1        1     0     -0.733607                1       -0.177294   \n",
       "1    1        0     0      0.055928                1       -0.350235   \n",
       "2    1        1     1      2.029767                1       -0.254156   \n",
       "3    0        1     1     -0.733607                0       -0.311803   \n",
       "4    1        0     1     -0.536224                1       -0.350235   \n",
       "\n",
       "   two_year_recid  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode variables with dummy variables\n",
    "df['sex'] = df['sex'].apply(lambda sex: 0 if sex == 'Female' else 1)\n",
    "df['age_cat'] = df['age_cat'].apply(lambda age_cat: 2 if age_cat == '> 45' else(1 if age_cat == '25 - 45' else 0))\n",
    "df['race'] = df['race'].apply(lambda race: 0 if race == 'African-American' else 1)\n",
    "df['c_charge_degree'] = df['c_charge_degree'].apply(lambda c_charge_degree: 0 if c_charge_degree == 'M' else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d1f1c",
   "metadata": {},
   "source": [
    "Create a function to process the data to obtain the target variable, the sensitive attribute and the remaining dataframe with the remaining features. We also perform a shuffle so that we can split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24e1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vars to store features\n",
    "features = ['sex', 'age_cat', 'priors_count', 'c_charge_degree', 'length_of_stay']\n",
    "sensitive = 'race'\n",
    "target = 'two_year_recid'\n",
    "\n",
    "# Function to process and shuffle data\n",
    "def process_df(df):\n",
    "    y_label = df[target]\n",
    "    protected_attr = df[sensitive]\n",
    "    df_new = df[features]\n",
    "    y_label, protected_attr, df_new = shuffle(y_label, protected_attr, df_new, random_state = 617)\n",
    "    \n",
    "    return y_label.to_numpy(), protected_attr.to_numpy(), df_new.to_numpy()\n",
    "\n",
    "# Split data into train and test\n",
    "y_label, protected_attr, df_new =  process_df(df)\n",
    "train_index = int(len(df_new) * 0.7)\n",
    "x_train, y_train, race_train = df_new[:train_index], y_label[:train_index], protected_attr[:train_index]\n",
    "x_test, y_test, race_test = df_new[train_index:], y_label[train_index:],protected_attr[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8963532",
   "metadata": {},
   "source": [
    "We also created a function to determine the p-rule (p%) and a function to compute calibration.\n",
    "\n",
    "+ **Protected**: Caucasians (i.e., `race == 1`)\n",
    "+ **Not protected**: African-Americans (i.e., `race == 0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2bb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute p-rule\n",
    "def p_rule(sensitive_var, y_pred):\n",
    "    protected = np.where(sensitive_var == 1)[0]\n",
    "    not_protected = np.where(sensitive_var == 0)[0]\n",
    "    protected_pred = np.where(y_pred[protected] == 1)\n",
    "    not_protected_pred = np.where(y_pred[not_protected] == 1)\n",
    "    protected_percent = protected_pred[0].shape[0]/protected.shape[0]\n",
    "    not_protected_percent = not_protected_pred[0].shape[0]/not_protected.shape[0]\n",
    "    ratio = min(protected_percent/not_protected_percent, not_protected_percent/protected_percent)\n",
    "    \n",
    "    return ratio, protected_percent, not_protected_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0f47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute calibration\n",
    "def calibration(sensitive_var, y_pred, y_true):\n",
    "    protected_point = np.where(sensitive_var == 1)[0]\n",
    "    y_predcau = y_pred[protected_point]\n",
    "    y_truecau = y_true[protected_point]\n",
    "    pcau = sum(y_predcau==y_truecau)/len(y_truecau)\n",
    "    not_protected_point = np.where(sensitive_var == 0)[0]\n",
    "    y_predafa = y_pred[not_protected_point]\n",
    "    y_trueafa = y_true[not_protected_point]\n",
    "    pafa = sum(y_predafa==y_trueafa)/len(y_trueafa)\n",
    "    calibration = abs(pcau-pafa)\n",
    "    return(calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70568a58",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression <a class=\"anchor\" id=\"lr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b00da9",
   "metadata": {},
   "source": [
    "### 3.1 Training unconstrained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004c9fa",
   "metadata": {},
   "source": [
    "First we train a baseline, unconstained classifier to evaluate its accuracy and p-rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d18c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.932367</td>\n",
       "      <td>53.771942</td>\n",
       "      <td>29.312425</td>\n",
       "      <td>54.512490</td>\n",
       "      <td>1.482763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>64.957746</td>\n",
       "      <td>61.642720</td>\n",
       "      <td>33.888889</td>\n",
       "      <td>54.976303</td>\n",
       "      <td>1.005793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0         LR  Train     66.932367   53.771942      29.312425   \n",
       "1         LR   Test     64.957746   61.642720      33.888889   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          54.512490         1.482763  \n",
       "1          54.976303         1.005793  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model and print results\n",
    "clf = LogisticRegression(random_state = 0).fit(x_train, y_train)\n",
    "coeff = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n",
    "results_lr = {\"Classifier\": [\"LR\", \"LR\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [clf.score(x_train, y_train)*100, clf.score(x_test, y_test)*100],\n",
    "              \"P-rule (%)\": [p_rule(race_train, clf.predict(x_train))[0]*100, p_rule(race_test, clf.predict(x_test))[0]*100],\n",
    "              \"Protected (%)\": [p_rule(race_train, clf.predict(x_train))[1]*100, p_rule(race_test, clf.predict(x_test))[1]*100],\n",
    "              \"Not protected (%)\": [p_rule(race_train, clf.predict(x_train))[2]*100, p_rule(race_test, clf.predict(x_test))[2]*100],\n",
    "              \"Calibration (%)\": [calibration(race_train, clf.predict(x_train), y_train)*100, calibration(race_test, clf.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f2cfb",
   "metadata": {},
   "source": [
    "### 3.2 Optimizing classifier accuracy subject to fairness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75eea19",
   "metadata": {},
   "source": [
    "Now we optimize accuracy subject to fairness constraints. The details can be found in Section 3.2 of the paper on [Fairness Constraints: Mechanisms for Fair Classification](https://arxiv.org/abs/1507.05259). Notice that setting `{'race': 0}` means that the classifier should achieve 0 covariance between the sensitive feature (`race`) value and distance to the decision boundary. A 0 covariance would mean no correlation between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bec9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting flags\n",
    "apply_fairness_constraints = 1 # set this flag to 1 since we want to optimize accuracy subject to fairness constraints\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = None\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "x_control = {'race': race_train}\n",
    "\n",
    "# Train model\n",
    "np.random.seed(100)\n",
    "w = ut.train_model(x_train,\n",
    "                   y_train,\n",
    "                   x_control,\n",
    "                   lf._logistic_loss,\n",
    "                   apply_fairness_constraints,\n",
    "                   apply_accuracy_constraint,\n",
    "                   sep_constraint,\n",
    "                   sensitive_attrs,\n",
    "                   sensitive_attrs_to_cov_thresh,\n",
    "                   gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae25c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit coefficients/weights into logistic regression in sklearn\n",
    "m = LogisticRegression()\n",
    "m.coef_= w.reshape((1,-1))\n",
    "m.intercept_ = 0\n",
    "m.classes_ = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603d611d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>48.454106</td>\n",
       "      <td>99.939857</td>\n",
       "      <td>99.819059</td>\n",
       "      <td>99.879130</td>\n",
       "      <td>14.021048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>46.084507</td>\n",
       "      <td>99.955856</td>\n",
       "      <td>99.861111</td>\n",
       "      <td>99.905213</td>\n",
       "      <td>9.535940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0       C-LR  Train     48.454106   99.939857      99.819059   \n",
       "1       C-LR   Test     46.084507   99.955856      99.861111   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          99.879130        14.021048  \n",
       "1          99.905213         9.535940  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results\n",
    "results_clr = {\"Classifier\": [\"C-LR\", \"C-LR\"],\n",
    "               \"Set\": [\"Train\", \"Test\"],\n",
    "               \"Accuracy (%)\": [m.score(x_train, y_train)*100, m.score(x_test, y_test)*100],\n",
    "               \"P-rule (%)\": [p_rule(race_train, m.predict(x_train))[0]*100, p_rule(race_test, m.predict(x_test))[0]*100],\n",
    "               \"Protected (%)\": [p_rule(race_train, m.predict(x_train))[1]*100, p_rule(race_test, m.predict(x_test))[1]*100],\n",
    "               \"Not protected (%)\": [p_rule(race_train, m.predict(x_train))[2]*100, p_rule(race_test, m.predict(x_test))[2]*100],\n",
    "               \"Calibration (%)\": [calibration(race_train, m.predict(x_train), y_train)*100, calibration(race_test, m.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1faac2",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machine (SVM) <a class=\"anchor\" id=\"svm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5981c",
   "metadata": {},
   "source": [
    "The following SVM codes are an adaptation of the paper on [Fairness Constraints: Mechanisms for Fair Classification](https://arxiv.org/abs/1507.05259). Additional helper functions like `SVM_scratch.py`, `datapreprocess.py` and `helper.py`were adapted from this GitHub [repo](https://github.com/SreeranjaniD/Fairness-in-Classification-using-SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9381f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from SVM_scratch import *\n",
    "from datapreprocess import *\n",
    "from helper import *\n",
    "\n",
    "# Set variables needed for training\n",
    "x_control_train = {'race': race_train}\n",
    "x_control_test = {'race': race_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26574504",
   "metadata": {},
   "source": [
    "Here we define a function for the classifier, which trains the model based on the fairness constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b3a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for classifier\n",
    "def classifier(apply_fairness_constraints,loss_function,c,sensitive_attrs,max_iter=1000,epoch=50,lamb=1,lr=0.1,C=1,gamma=None):\n",
    "    svm =SVM()\n",
    "    w = svm.training(x_train,y_train, x_control_train, loss_function,C,max_iter,lamb,epoch,lr, apply_fairness_constraints, sensitive_attrs, c,gamma)\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "    distances_hyperplane_test = (np.dot(x_test, w)).tolist()\n",
    "    all_class_labels_assigned_test = np.sign(distances_hyperplane_test)\n",
    "    correlation_test_dict = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "    cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_hyperplane_test, x_control_test, sensitive_attrs)\n",
    "    ut.print_classifier_fairness_stats([test_score],correlation_test_dict, [cov_dict_test], sensitive_attrs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6632771",
   "metadata": {},
   "source": [
    "### 4.1 Training unconstrained SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2a19b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.835749</td>\n",
       "      <td>52.006786</td>\n",
       "      <td>26.296743</td>\n",
       "      <td>50.564061</td>\n",
       "      <td>1.120395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.183099</td>\n",
       "      <td>60.848593</td>\n",
       "      <td>30.972222</td>\n",
       "      <td>50.900474</td>\n",
       "      <td>2.262375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0        SVM  Train     66.835749   52.006786      26.296743   \n",
       "1        SVM   Test     65.183099   60.848593      30.972222   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          50.564061         1.120395  \n",
       "1          50.900474         2.262375  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model and print results\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "svm_model = SVC(kernel = 'linear', probability = True)\n",
    "\n",
    "# Train model and print results\n",
    "clf = svm_model.fit(x_train, y_train)\n",
    "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n",
    "results_svm = {\"Classifier\": [\"SVM\", \"SVM\"],\n",
    "               \"Set\": [\"Train\", \"Test\"],\n",
    "               \"Accuracy (%)\": [clf.score(x_train, y_train)*100, clf.score(x_test, y_test)*100],\n",
    "               \"P-rule (%)\": [p_rule(race_train, clf.predict(x_train))[0]*100, p_rule(race_test, clf.predict(x_test))[0]*100],\n",
    "               \"Protected (%)\": [p_rule(race_train, clf.predict(x_train))[1]*100, p_rule(race_test, clf.predict(x_test))[1]*100],\n",
    "               \"Not protected (%)\": [p_rule(race_train, clf.predict(x_train))[2]*100, p_rule(race_test, clf.predict(x_test))[2]*100],\n",
    "               \"Calibration (%)\": [calibration(race_train, clf.predict(x_train), y_train)*100, calibration(race_test, clf.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3b47b",
   "metadata": {},
   "source": [
    "### 4.2 Optimizing SVM classifier accuracy subject to fairness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e62089",
   "metadata": {},
   "source": [
    "Now we optimize accuracy subject to fairness constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "136511ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject to fairness constraints\n",
    "apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "loss_function = lf._hinge_loss\n",
    "sensitive_attrs = ['race']\n",
    "c = {'race': 0} # covariance threshold\n",
    "C = 1 # penalty term\n",
    "\n",
    "# gamma controls how much loss in accuracy we are willing to incur to achieve fairness \n",
    "# Increase in gamma decrease the accuracy to a certain limit \n",
    "# But we are setting it to None as we are not tuning gamma\n",
    "gamma = None\n",
    "epochs = 1000 # Number of epochs \n",
    "lamb = 1 # lambda \n",
    "lr = 0.1  # learning rate \n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241ab92",
   "metadata": {},
   "source": [
    "We defined a `csvm` function that returns the train and test scores, and the predicted values for train and test so that we can compute the accuracy and calibration scores later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "425cce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for training that returns scores\n",
    "def csvm(x_train, y_train, x_test, y_test, C, max_iter, lamb, epochs,lr, apply_fairness_constraints, \n",
    "         sensitive_attrs, sensitive_attrs_to_cov_thresh=c, gamma=None):\n",
    "    \n",
    "    svm = SVM()\n",
    "    w = svm.training(x_train, y_train, x_control_train, loss_function, C, max_iter, lamb, epochs, lr, \n",
    "                     apply_fairness_constraints, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "    y_test_predicted = np.sign(np.dot(x_test, w))\n",
    "    y_train_predicted = np.sign(np.dot(x_train, w))\n",
    "    \n",
    "    def get_accuracy(y, Y_predicted):\n",
    "        correct_answers = (Y_predicted == y).astype(int) # will have 1 when the prediction and the actual label match\n",
    "        accuracy = float(sum(correct_answers)) / float(len(correct_answers))\n",
    "        return accuracy, sum(correct_answers)\n",
    "\n",
    "    train_score, correct_answers_train = get_accuracy(y_train, y_train_predicted)\n",
    "    test_score, correct_answers_test = get_accuracy(y_test, y_test_predicted)\n",
    "    return train_score, test_score, correct_answers_train, correct_answers_test, y_test_predicted, y_train_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06dac958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running custom model with fairness constraints\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "train_score, test_score, correct_answers_train, correct_answers_test, y_test_predicted, y_train_predicted = csvm(x_train, y_train, x_test, y_test, C, max_iter, lamb, epochs,lr, apply_fairness_constraints, sensitive_attrs, sensitive_attrs_to_cov_thresh=c, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "879367bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>48.405797</td>\n",
       "      <td>99.939857</td>\n",
       "      <td>99.819059</td>\n",
       "      <td>99.879130</td>\n",
       "      <td>14.041072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>46.028169</td>\n",
       "      <td>99.955856</td>\n",
       "      <td>99.861111</td>\n",
       "      <td>99.905213</td>\n",
       "      <td>9.441153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0      C-SVM  Train     48.405797   99.939857      99.819059   \n",
       "1      C-SVM   Test     46.028169   99.955856      99.861111   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          99.879130        14.041072  \n",
       "1          99.905213         9.441153  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results\n",
    "results_csvm = {\"Classifier\": [\"C-SVM\", \"C-SVM\"],\n",
    "                \"Set\": [\"Train\", \"Test\"],\n",
    "                \"Accuracy (%)\": [train_score*100, test_score*100],\n",
    "                \"P-rule (%)\": [p_rule(race_train, y_train_predicted)[0]*100, p_rule(race_test, y_test_predicted)[0]*100],\n",
    "                \"Protected (%)\": [p_rule(race_train, y_train_predicted)[1]*100, p_rule(race_test, y_test_predicted)[1]*100],\n",
    "                \"Not protected (%)\": [p_rule(race_train, y_train_predicted)[2]*100, p_rule(race_test, y_test_predicted)[2]*100],\n",
    "                \"Calibration (%)\": [calibration(race_train, y_train_predicted, y_train)*100, calibration(race_test, y_test_predicted, y_test)*100]}\n",
    "pd.DataFrame(results_csvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cfa56",
   "metadata": {},
   "source": [
    "## 5. Information Theoretic Measures for Fairness-Aware Feature Selection (FFS) <a class=\"anchor\" id=\"ffs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4166a3",
   "metadata": {},
   "source": [
    "This is another method to deal with machine learning fairness and we recreated the framework that was described in the paper, [Information Theoretic Measures for Fairness-aware Feature selection (FFS)](https://arxiv.org/abs/2106.00772). In short, from the joint statistics of the data, the framework proposes that two information theoretic measures can be used to quantify the accuracy and discrmination aspect for each subset of the feature space. We then compute the Shapley coefficients for each feature to capture its effect on the sensitive/protected group (i.e., `race`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c779e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "df2 = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "\n",
    "# Split data into target variable, sensitive variables and the other features\n",
    "train_set = set_split_train(process_df2(df2)[0], process_df2(df2)[1], process_df2(df2)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01c2862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Shapley Discrimination</th>\n",
       "      <th>Shapley Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>priors_count</td>\n",
       "      <td>25508.281363</td>\n",
       "      <td>1.264251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>length_of_stay</td>\n",
       "      <td>25483.034007</td>\n",
       "      <td>1.048422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_cat</td>\n",
       "      <td>21627.423734</td>\n",
       "      <td>1.096104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sex</td>\n",
       "      <td>20962.580750</td>\n",
       "      <td>0.941318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_charge_degree</td>\n",
       "      <td>20764.750822</td>\n",
       "      <td>1.036236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Shapley Discrimination  Shapley Accuracy\n",
       "0     priors_count            25508.281363          1.264251\n",
       "1   length_of_stay            25483.034007          1.048422\n",
       "2          age_cat            21627.423734          1.096104\n",
       "3              sex            20962.580750          0.941318\n",
       "4  c_charge_degree            20764.750822          1.036236"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Shapley coefficients and display results sorted from highest discrimination\n",
    "accuracy, discriminate = shapley_Cal(train_set)[0], shapley_Cal(train_set)[1]\n",
    "shapley_results = shapley_df(discriminate,accuracy)\n",
    "shapley_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6159149",
   "metadata": {},
   "source": [
    "Based on the results, `priors_count` has the greatest impact on discrimination, but it also has the greatest effect on accuracy, which may be a problem if we removed it from the classifier. On the other hand, `length_of_stay` has relatively high discrimination but it does not have a serious impact on accuracy when compared with the rest; removing it seems like a good choice. Therefore, the feature set to be used for the LR and SVM below would be:\n",
    "\n",
    "+ `sex`\n",
    "+ `age_cat`\n",
    "+ `priors_count`\n",
    "+ `c_charge_degree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e88b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vars to store features (removed 'length_of_stay')\n",
    "features = ['sex', 'age_cat', 'priors_count', 'c_charge_degree']\n",
    "sensitive = 'race'\n",
    "target = 'two_year_recid'\n",
    "\n",
    "# Split data into train and test\n",
    "y_label, protected_attr, df_new =  process_df(df)\n",
    "train_index = int(len(df_new) * 0.7)\n",
    "x_train, y_train, race_train = df_new[:train_index], y_label[:train_index], protected_attr[:train_index]\n",
    "x_test, y_test, race_test = df_new[train_index:], y_label[train_index:],protected_attr[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0a131",
   "metadata": {},
   "source": [
    "### 5.1 Logistic regression using features from FFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d32e096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFS-LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>67.053140</td>\n",
       "      <td>54.25751</td>\n",
       "      <td>30.036188</td>\n",
       "      <td>55.358582</td>\n",
       "      <td>1.684213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFS-LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.070423</td>\n",
       "      <td>61.94468</td>\n",
       "      <td>34.583333</td>\n",
       "      <td>55.829384</td>\n",
       "      <td>0.115192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0     FFS-LR  Train     67.053140    54.25751      30.036188   \n",
       "1     FFS-LR   Test     65.070423    61.94468      34.583333   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          55.358582         1.684213  \n",
       "1          55.829384         0.115192  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model and print results\n",
    "clf = LogisticRegression(random_state = 0).fit(x_train, y_train)\n",
    "coeff = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n",
    "results_ffs_lr = {\"Classifier\": [\"FFS-LR\", \"FFS-LR\"],\n",
    "                  \"Set\": [\"Train\", \"Test\"],\n",
    "                  \"Accuracy (%)\": [clf.score(x_train, y_train)*100, clf.score(x_test, y_test)*100],\n",
    "                  \"P-rule (%)\": [p_rule(race_train, clf.predict(x_train))[0]*100, p_rule(race_test, clf.predict(x_test))[0]*100],\n",
    "                  \"Protected (%)\": [p_rule(race_train, clf.predict(x_train))[1]*100, p_rule(race_test, clf.predict(x_test))[1]*100],\n",
    "                  \"Not protected (%)\": [p_rule(race_train, clf.predict(x_train))[2]*100, p_rule(race_test, clf.predict(x_test))[2]*100],\n",
    "                  \"Calibration (%)\": [calibration(race_train, clf.predict(x_train), y_train)*100, calibration(race_test, clf.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_ffs_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275028e9",
   "metadata": {},
   "source": [
    "### 5.2 SVM using features from FFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfcdcba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFS-SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.859903</td>\n",
       "      <td>52.990595</td>\n",
       "      <td>28.950543</td>\n",
       "      <td>54.63336</td>\n",
       "      <td>1.965515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFS-SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.577465</td>\n",
       "      <td>61.602509</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>54.78673</td>\n",
       "      <td>0.664165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0    FFS-SVM  Train     66.859903   52.990595      28.950543   \n",
       "1    FFS-SVM   Test     65.577465   61.602509      33.750000   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0           54.63336         1.965515  \n",
       "1           54.78673         0.664165  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel = 'linear', probability = True)\n",
    "\n",
    "# Train model and print results\n",
    "clf = svm_model.fit(x_train, y_train)\n",
    "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n",
    "results_ffs_svm = {\"Classifier\": [\"FFS-SVM\", \"FFS-SVM\"],\n",
    "                   \"Set\": [\"Train\", \"Test\"],\n",
    "                   \"Accuracy (%)\": [clf.score(x_train, y_train)*100, clf.score(x_test, y_test)*100],\n",
    "                   \"P-rule (%)\": [p_rule(race_train, clf.predict(x_train))[0]*100, p_rule(race_test, clf.predict(x_test))[0]*100],\n",
    "                   \"Protected (%)\": [p_rule(race_train, clf.predict(x_train))[1]*100, p_rule(race_test, clf.predict(x_test))[1]*100],\n",
    "                   \"Not protected (%)\": [p_rule(race_train, clf.predict(x_train))[2]*100, p_rule(race_test, clf.predict(x_test))[2]*100],\n",
    "                   \"Calibration (%)\": [calibration(race_train, clf.predict(x_train), y_train)*100, calibration(race_test, clf.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_ffs_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb6fde",
   "metadata": {},
   "source": [
    "## 6. Evaluation <a class=\"anchor\" id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce5ea2",
   "metadata": {},
   "source": [
    "In this final section, we evaluate the performance of each model using **accuracy** and **calibration**. Although there are other metrics listed below, we will only select the best model using the two mentioned metrics; the other metrics like p-rule are listed for discussion purposes. All the scores below are on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e24a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifier</th>\n",
       "      <th>LR</th>\n",
       "      <th>C-LR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>C-SVM</th>\n",
       "      <th>FFS-LR</th>\n",
       "      <th>FFS-SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Set</th>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <td>64.957746</td>\n",
       "      <td>46.084507</td>\n",
       "      <td>65.183099</td>\n",
       "      <td>46.028169</td>\n",
       "      <td>65.070423</td>\n",
       "      <td>65.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-rule (%)</th>\n",
       "      <td>61.64272</td>\n",
       "      <td>99.955856</td>\n",
       "      <td>60.848593</td>\n",
       "      <td>99.955856</td>\n",
       "      <td>61.94468</td>\n",
       "      <td>61.602509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protected (%)</th>\n",
       "      <td>33.888889</td>\n",
       "      <td>99.861111</td>\n",
       "      <td>30.972222</td>\n",
       "      <td>99.861111</td>\n",
       "      <td>34.583333</td>\n",
       "      <td>33.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not protected (%)</th>\n",
       "      <td>54.976303</td>\n",
       "      <td>99.905213</td>\n",
       "      <td>50.900474</td>\n",
       "      <td>99.905213</td>\n",
       "      <td>55.829384</td>\n",
       "      <td>54.78673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibration (%)</th>\n",
       "      <td>1.005793</td>\n",
       "      <td>9.53594</td>\n",
       "      <td>2.262375</td>\n",
       "      <td>9.441153</td>\n",
       "      <td>0.115192</td>\n",
       "      <td>0.664165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classifier                LR       C-LR        SVM      C-SVM     FFS-LR  \\\n",
       "Set                     Test       Test       Test       Test       Test   \n",
       "Accuracy (%)       64.957746  46.084507  65.183099  46.028169  65.070423   \n",
       "P-rule (%)          61.64272  99.955856  60.848593  99.955856   61.94468   \n",
       "Protected (%)      33.888889  99.861111  30.972222  99.861111  34.583333   \n",
       "Not protected (%)  54.976303  99.905213  50.900474  99.905213  55.829384   \n",
       "Calibration (%)     1.005793    9.53594   2.262375   9.441153   0.115192   \n",
       "\n",
       "Classifier           FFS-SVM  \n",
       "Set                     Test  \n",
       "Accuracy (%)       65.577465  \n",
       "P-rule (%)         61.602509  \n",
       "Protected (%)          33.75  \n",
       "Not protected (%)   54.78673  \n",
       "Calibration (%)     0.664165  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results summary\n",
    "results_summary = pd.concat([pd.DataFrame(results_lr).iloc[1,], pd.DataFrame(results_clr).iloc[1,],\n",
    "                             pd.DataFrame(results_svm).iloc[1,], pd.DataFrame(results_csvm).iloc[1,],\n",
    "                             pd.DataFrame(results_ffs_lr).iloc[1,], pd.DataFrame(results_ffs_svm).iloc[1,]], axis=1)\n",
    "results_summary.columns = results_summary.iloc[0]\n",
    "results_summary = results_summary.iloc[1:,:]\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bb281",
   "metadata": {},
   "source": [
    "We will evaluate the models using accuracy and calibration as defined by the project guidelines. Based on that, FFS-LR and FFS-SVM performed best in calibration and accuracy. Both the FFS models had similar accuracy and calibration scores, but we will select FFS-LR as the model of choice since it is more interpretable and simpler to implement as compared to SVM.\n",
    "\n",
    "Of course, if parity (or p-rule) is the metric of choice for making model selection, then we would recommend the constrained models because they performed well on p-rule (close to 100%), albeit with a trade-off in accuracy and calibration. To note, the constrained models did not perform so well on calibration, which is theoretically possible because the constraints were optimizing parity (i.e., p-rule) and not calibration. As can be seen from the results, the p-rule for both constrained models has been optimized close to 100% because of this.\n",
    "\n",
    "Lastly, although the FFS feature selection portion took slightly longer to run than the other models (~10 sec), it is not very detrimental to our project due to the small feature space. It might, however, have a greater impact on larger datasets with more rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4818b",
   "metadata": {},
   "source": [
    "## 7. References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23758ff6",
   "metadata": {},
   "source": [
    "Research papers:\n",
    "+ https://arxiv.org/abs/2106.00772\n",
    "+ https://arxiv.org/abs/1507.05259\n",
    "+ https://people.mpi-sws.org/~mzafar/papers/fatml_15.pdf\n",
    "\n",
    "Code and datasets:\n",
    "+ https://towardsdatascience.com/optimization-with-scipy-and-application-ideas-to-machine-learning-81d39c7938b8\n",
    "+ https://github.com/mbilalzafar/fair-classification/tree/master/disparate_impact\n",
    "+ https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis\n",
    "+ https://github.com/SreeranjaniD/Fairness-in-Classification-using-SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
